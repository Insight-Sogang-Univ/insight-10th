{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00b289f",
   "metadata": {},
   "source": [
    "# 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fd47c",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f06a685",
   "metadata": {},
   "source": [
    "- 어느방향으로 갈 것인가를 결정하는 것.\n",
    "- cost function을 바탕으로 오차를 줄여나가는 방식,paramerter업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf357a",
   "metadata": {},
   "source": [
    "## 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d10441",
   "metadata": {},
   "source": [
    "-  적당한 Learning rate을 설정하여 학습률을 통해 얼마나 움직일지 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef712c",
   "metadata": {},
   "source": [
    "- 미분값은 오직 방향만 결정 (미분값음수-오른쪾으로 점이 이동, 양수->왼쪽으로 점이 이동)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daace79d",
   "metadata": {},
   "source": [
    "## 문제점 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a07b06",
   "metadata": {},
   "source": [
    "- .cost function이 어떤 모양인지 예측할 수 없는 경우, local minimum에 지지 않도록 주의\n",
    "- 학습률을 너무 크게 설정하면 최적값에 수렴하지 못하고 다른곳으로 발산 \n",
    "    ->학습 도중에 학습률을 지속적으로 바꾸는 Adaptive Gradient Descent를 사용하여 해결 가능\n",
    "    -> 모멘텀 : 기울기에 관성을 부여하여 작은 기울기는 넘어가도록 설정\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c65c46",
   "metadata": {},
   "source": [
    "# 규제 선형 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be44c73",
   "metadata": {},
   "source": [
    "## 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca6223c",
   "metadata": {},
   "source": [
    "### 릿지 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc90fc",
   "metadata": {},
   "source": [
    "- 계수를 제곱한 기준으로 규제를 적용\n",
    "\n",
    "->allph매개 변수값을 통해 규제의 정도 조절가능\n",
    "\n",
    "- alpha커질경우 : 규제정도가 세지므로 계수값을 줄이고 조금 더 과소적합되도록 유도\n",
    "\n",
    "- alpha작아질 경우 : 계수를 줄이는 역할이 줄어들고 다중 선형회귀 모델과 유사해지므로 과대적합될 가능성 커짐\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78768fe",
   "metadata": {},
   "source": [
    "### 라쏘 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b6c7a1",
   "metadata": {},
   "source": [
    "- 계수의 절댓값 기준으로 규제를 적용\n",
    "- W의 절댓값에 페널티를 부여하는 L1규제를 선형 회귀에 적용한 것이 라쏘(Lasso)회귀\n",
    "- L1규제는 alpha*||W|| ,불필요한 회귀 계수를 급격하게 감소시켜 0으로 만들고 제거\n",
    "- 라쏘는 0으로 만들기가 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583211ea",
   "metadata": {},
   "source": [
    "### 엘라스틱넷 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae48b40c",
   "metadata": {},
   "source": [
    "- L2규제와 L1규제를 결합한 회귀\n",
    "- 단점 : 수행시간이 상대적으로 오래 걸림\n",
    "- 주요 피라미터 \n",
    "    -alph, 11_ratio\n",
    "- 규제 :  a*L1 + b*L2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e974b7",
   "metadata": {},
   "source": [
    "## 편향과 분산간의 Trade-Off관계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725f461",
   "metadata": {},
   "source": [
    "- 과소적합 (높은 편향, 낮은 분산): 모델 복잡도를 높이고, 더 많은 특성을 사용하거나 다양한 모델 시도\n",
    "- 과대적합(낮은 편향, 높은 분산): 더 많은 데이터를 수집하거나, 특성 선택/추출, 규제(Regularization)를 사용하여 모델 복잡도를 줄임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706c7da",
   "metadata": {},
   "source": [
    "# Scailing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522018c",
   "metadata": {},
   "source": [
    "정의 : 모든 피쳐들의 데이터 분포나 범위를 동일하게 조정하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df1ed0",
   "metadata": {},
   "source": [
    "특징 \n",
    "- 피쳐별로 데이터의 범위가 다르면 피쳐를 비교하기가 어려워 머신러닝이 잘 작동하지 않음\n",
    "-  모든 특성의 범위(분포)를 같게 만들어 잘 작동할 수 있도록 만드는 과정을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b079d0",
   "metadata": {},
   "source": [
    "##### 주요 개념                          \n",
    "##### 표준화 : \n",
    "- 입력된 값들의 정규 분포를 평균이 0 이고 분산이 1 인  표준 정규 분포로 변환하는 것\n",
    "- 데이터가 평균으로부터 얼마나 떨어져 있는지 나타냄\n",
    "- 특정 범위를 벗어난 데이터는 outlier로 간주하고 제거     \n",
    "##### 정규화 :\n",
    " - 입력된 x 값들을 모두 0과 1사이의 값으로 변환해 서로 다른 피쳐의 크기를 통일하는 개념\n",
    "- 데이터의 상대적 크기에 대한 영향을 줄이기 위해 데이터의 범위를 0-1로 변환\n",
    "- 가장 큰 값이 1이고, 가장 작은 값은 0으로 변환\n",
    "- 모든 값이 0과 1사이로 변환되기 때문에 비교하기 용이\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc70f66",
   "metadata": {},
   "source": [
    "##### 스케일링 변환 시 주의사항"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804a95d",
   "metadata": {},
   "source": [
    "사이킷런(Scikit-Learn)  :  sciPy와 Toolkit을 합친 파이썬 기반 머신러닝용 라이브러리\n",
    "- 습 데이터(Training Data) :  모델이 학습하는 데 사용되는 데이터\n",
    "- 테스트 데이터(Test Data)  :  모델이 학습된 후에 모델의 성능을 검증하기 위해 사용되는 데이터\n",
    "    \n",
    "- 테스트 데이터로 다시 새로운 스케일링 기준을 만들어 버리면 학습 데이터와 테스트 데이터의 스케일링 기준 정보가 달라지기 때문에, 테스트 데이터에는 fit() 적용하면 안된다. \n",
    "- 일반적으로 타겟(y) 데이터에 대한 스케일링은 진행하지 않는다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee27caf",
   "metadata": {},
   "source": [
    "##### 스케일링 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b58d76",
   "metadata": {},
   "source": [
    "- StandardScaler():\n",
    "특성(feature)의 평균을 0, 분산을 1로 맞추는 표준화(Standardization)를 수행\n",
    "- MinMaxScaler():\n",
    "모든 피쳐들이 0과 1사이의 데이터 값을 갖도록 변환\n",
    "- MaxAbsScaler():\n",
    "데이터가 -1과 1 사이에 위치하도록 스케일링\n",
    "- RobustScaler():\n",
    "데이터의 중앙값이 0, IQE(Q3-Q1) = 1이 되도록 스케일링\n",
    "- Normalizer():\n",
    "각 데이터 포인트(행)의 norm(크기)을 1로 만들어주는 스케일링 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ca93c",
   "metadata": {},
   "source": [
    "# 차원 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb3f500",
   "metadata": {},
   "source": [
    "- 정의 : 차원(次元)은 수학에서 공간 내에 있는 점 등의 위치를 나타내기 위해 필요한 축의 개수\n",
    "- 데이터에서 차원 = 변수의 수 --> 차원이 크면 시각화가 어렵고, 이해하기 어렵고, 분석하기도 어려움\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa071e",
   "metadata": {},
   "source": [
    "##### 대표적인 차원 축소 알고리즘 \n",
    " (PCA,LDA,SVD,NMF)\n",
    " ##### *PCA(주성분 분석, Principal Component Analysis)*\n",
    " 고차원 데이터를 기존의 분산을 최대한 보존하는 선형 독립의 새로운 변수들로 변환: 여러 변수 간에 존재하는 상관관계를 이용해 이를 대표하는 주성분을 추출해 차원 축소\n",
    " ##### LDA\n",
    " PCA처럼 입력 데이터 세트를 저차원 공간에 투영해 차원을 축소하는 기법으로 PCA와 매우 유사 \n",
    " 차이는 LDA는 지도학습의 분류에서 사용하기 쉽도록 개별 클래스를 분별할 수 있는 기준을 최대한 유지하면서 차원 축소\n",
    " ##### SVD\n",
    " SVD는 정사각행렬이 아닌 m*n 형태의 다양한 행렬을 분해 (특이값분해)\n",
    " ##### NMF\n",
    " 하나의 객체정보를 음수를 포함하지 않은 두 개의 부분 정보로 인수분해하는 방법"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
