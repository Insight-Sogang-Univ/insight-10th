# 경사하강법
## 개요
cost function을 바탕으로 오차를 줄여나가는 parameter를 업데이트 하는 방식중 하나  
기울기가 감소하다가 0이되는 지점을 최솟값이라고 가정하는 방식  
->현재 지점의 값에서 미분값을 뺀 방향으로 현재 값이 업데이트 된다. 최소지점에 다다르면  
기울기가 0이되고 즉 미분값이 0이되어 더이상 현재값이 업데이트되지 않음.  
MSE, RMSE와 같은 함수는 경사하강법이 증명됨  
## 한계점  
**한계1:이때 단순히 현재값-미분값으로만 업데이트 하면 최솟값에 멀어지는 경우가 발생할 수도 있다.(학습률 즉 현재값을 업데이트하는 비율을 정해주면서 이를 해결한다.)**  

**한계2:딥러닝시 극소점이 여러개인 경우 최소점을 특정할 수가 없다(이를 탈출하는 알고리즘 존재)**    

# 규제선형모델

## 개요
훈련세트에 과대적합되지 않도록 규제하는 모델임  
선형 회귀 모델에서는 특성에 곱해지는 계수의 크기를 조정하는 것을 의미  
rss(실제 값과 예측값의 차이 최소화)방식은 계수가 쉽게 커지게 되는 경향존재  
  
따라서 rss최소화와 계수값이 커지는 과적합의 방지가 균형을 이루어야함.  
->최적 모델을 위한 Cost 함수 목표 = Min(학습데이터 잔차 오류 최소화 + 회귀계수 크기 제어)  
->Min(RSS(W) +alpha*||W||^2
여기서 alpha는 학습 데이터 적합 정도와 회귀계수 값의 크기 제어를 수행하는 튜닝 파라미터  

alpha=0인 경우는 W가 커도 "alpha∗||W||22"값이 0이 되어 비용 함수는 Min(RSS(W))가 된다.  

alpha=무한대인 경우 "alpha∗||W||22"도 무한대가 되므로 비용 함수는 W를 0에 가깝게 최소화 해야 한다.  

## 규제 선형 모델 종류
(1)릿지 회귀  
계수를 제곱한 기준으로 규제를 적용 회귀

(2)라쏘 회귀  
계수의 절댓값을 기준으로 규제를 적용 회귀

(3)엘라스틱넷 회귀  
L2(릿지) L1(라쏘) 결합한 회쉬

**편향과 분산의 trade-off관계**'
과소적합->높은 편향, 낮은 분산, 모델 복잡도를 높이고 더 많은 특성을 사용하거나 다양한 모델 시도
과대적합->낮은 편향, 높은 분산, 더 많은 데이터를 수집하거나 특성 선택/ 추출 규제로 복잡도 감소 
# 스케일링
## 개념
데이터 전처리 과정 중 하나로, 모든 피쳐들의 데이터 분포나 범위를 동일하게 조정하는 과정
표준화:입력된 값들의 정규분포를 평균0,분산1인 표준 정규 분포로 변환 
정규화:입력된 x값들을 모두 0과 1사이의 값으로 변환해 서로 다른 피쳐의 크기를 통일하는 개념


# 차원축소
## 개념
차원은 점을 표현하는데 필요한 축의 개수

차원이 클수록 시각화가 어려우면 직관적으로 이해하고 분석하기도 어렵다.  
차원이 클수록 데이터 밀도를 유지하기 어렵다.  
차원이 클수록 데이터의 과적합 문제가 발생함  

차원을 줄여야 분석에 유리하다.차원을 줄이는 다양한 기법을 차원 축소라고 일컷는다.

## 대표적인 차원 축소 알고리즘(PCA, LDA, SVD, NMF)
### PCA(주성분분석)
특정 개수의 변수로 전체 변수의 분산에 대해 설명할 수 있을때 특정 개수만 채택하는 기법
변수간 상관관계를 이용해 주성분을 추출하여 차원축소
차원을 줄이기 위해 축을 회전시켜 새로운 축을 찾아내는 기법
고차원 데이터를 기존의 분산을 최대한 보존하는 선형 독립의 새로운 변수들로 변화
분산이 가장 넓은 지역을 찾은 후 분산 보존함

### LDA(선형 판별 분석)
PCA처럼 입력 데이터 세트를 저차원 공간에 투영해 차원을 축소하는 기법으로 PCA와 매우 유사함

중요한 차이는 LDA는 지도학습의 분류에서 사용하기 쉽도록 개별 클래스를 분별할 수 있는 기준을 최대한 유지하면서 차원 축소

### SVD(특이값 분해)
SVD는 정사각행렬이 아닌 m*n 형태의 다양한 행렬을 분해하며, 이를 특이값 분해라 말한다

### NMF(비음수 행렬 분해)
하나의 객체 정보를 음수를 포함하지 않는 두개의 부분 정보로 인수분해하는 방법
음수를 포함하지 않은 행렬  $m \times n$ 행렬 $R$ 을 음수를 포함하지 않은 행렬 $W, H$의 곱으로 분해하여 의미 있는 특징을 추출하는 기법
NMF는 대량의 정보를 의미 특징과 의미 변수로 나누어 효율적으로 표현할 수 있는 방법
