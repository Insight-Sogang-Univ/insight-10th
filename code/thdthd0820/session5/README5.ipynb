{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc35a39c",
   "metadata": {},
   "source": [
    "# 회귀 심화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c46a8",
   "metadata": {},
   "source": [
    "## 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e7f9e",
   "metadata": {},
   "source": [
    "### 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a7c84",
   "metadata": {},
   "source": [
    "1. 원리\n",
    "    - 최소값에 도달 : 기울기(미분 값)가 0이 되는 시점에 변화를 멈추고 최소값에 도달\n",
    "2. 학습률\n",
    "    - 미분 값 : 오직 방향만 결정, 얼마나 움직일지를 정해주지 않으면 오히려 최소값에서 멀어질 수 있음\n",
    "    - 학습률 : 얼마나 움직일지, 즉 오차의 최소값을 찾기 위해 결정해야하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed6f24",
   "metadata": {},
   "source": [
    "### 경사하강법의 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2502d4",
   "metadata": {},
   "source": [
    "1. Local Minima\n",
    "    - 모든 cost function이 하나의 최소값을 가지는 형태가 아님\n",
    "    - Global Minima가 아닌 Local Minima에 빠지는 경우 문제가 될 수 있음\n",
    "2. Step Size를 잘못 설정\n",
    "    - 학습률이 너무 큰 경우 : 최적값에 수렴하지 못하고 발산\n",
    "    - 학습률이 너무 낮은 경우 : 발산하지 않는 대신, 최적값에 수렴하는 시간 오래 소요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d8a94",
   "metadata": {},
   "source": [
    "### 해결책"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c35bf",
   "metadata": {},
   "source": [
    "1.  Adaptive Gradient Descent : 학습 도중에 학습률을 지속적으로 바꿔줌\n",
    "2. 모멘텀 : 기울기에 관성을 부여하여, Local Minima를 탈출할 수 있도록 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eec4e5",
   "metadata": {},
   "source": [
    "## 규제선형모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d8f73",
   "metadata": {},
   "source": [
    "### 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a2d6b",
   "metadata": {},
   "source": [
    "1. 등장 배경\n",
    "    - 모델이 훈련셋에 과적합되지 않도록 '규제'\n",
    "2. 규제 방식\n",
    "    - L1 규제 : W의 절대값에 페널티 부여 (Lasso 회귀)\n",
    "    - L2 규제 : W의 제곱에 페널티 부여 (Ridge 회귀)\n",
    "    - L1+L2 규제 : (Elastic Net 회귀)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571809bc",
   "metadata": {},
   "source": [
    "### 규제선형모델의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2b3b1",
   "metadata": {},
   "source": [
    "1. 릿지 회귀\n",
    "    - 계수를 제곱한 기준으로 규제 적용 (L2)\n",
    "    - alpha 값 커질수록 과소적합 유도 / 작아질수록 과대적합 가능성\n",
    "2. 라쏘 회귀\n",
    "    - 계수의 절대값 기준으로 규제를 적용 (L1)\n",
    "    - 라쏘는 회귀 계수를 0으로 만들기 가능, 따라서 유용한 feature를 선택할 수 있음\n",
    "3. 엘라스틱넷 회귀\n",
    "    - 배경 : alpha 값에 따라 회귀계수 값이 급변하는 단점을 완화하기 위해 L2규제를 라쏘 회귀에 추가\n",
    "    - 단점 : 시간이 상대적으로 오래 걸림\n",
    "    - 파라미터 : a는 L1규제의 alpha값, b는 L2규제의 alpha값일 때, 엘라스틱넷의 alpha파라미터 값은 a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ea1e1",
   "metadata": {},
   "source": [
    "### 편향과 분산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b2059",
   "metadata": {},
   "source": [
    "- trade-off 관계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e07733",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cbd18",
   "metadata": {},
   "source": [
    "### 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10078f",
   "metadata": {},
   "source": [
    "- 데이터 전처리 과정, 모든 feature들의 데이터 분포, 범위를 동일하게 조정\n",
    "    - 표준화 : 입력된 값들의 정규 분포를 평균 0, 분산 1인 표준 정규분포로 변환\n",
    "    - 정규화 : 입력된 x값들을 모두 0~1 사이 값으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f9eb4",
   "metadata": {},
   "source": [
    "### 주의사항"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c9e0f8",
   "metadata": {},
   "source": [
    "1. 테스트 데이터에는 fit() 함수를 적용하지 말 것 \n",
    "    - 테스트 데이터로 새로운 스케일링 기준을 만들면, 학습 데이터와 테스트 데이터의 스케일링 기준 정보가 달라지기 때문\n",
    "    - 가능하면 전체 데이터에 스케일링을 적용, 이후에 학습/테스트 데이터를 분리\n",
    "2. 일반적으로 Y (타겟 데이터)에 대한 스케일링은 진행하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596c955",
   "metadata": {},
   "source": [
    "### 스케일링 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724b7ce",
   "metadata": {},
   "source": [
    "1. StandardScaler()\n",
    "    - 피쳐의 평균을 0, 분산을 1로 맞추는 표준화 수행\n",
    "    - 회귀보다 분류에 유용\n",
    "2. MinMaxScaler()\n",
    "    - 피쳐들이 0과 1사이의 값을 갖도록 변환\n",
    "    - 분류보다 회귀에 유용\n",
    "3. MaxAbsScaler()\n",
    "    - 데이터가 -1과 1 사이에 위치하도록 스케일링\n",
    "4. RobustScaler()\n",
    "    - 데이터의 중앙값이 0, IQE (Q3-Q1) =1이 되도록 스케일링\n",
    "5. Normalizer()\n",
    "    - 각 행의 크기를 1로 만들어주는 스케일링 (행마다 정규화)\n",
    "    - 1~4번의 방법은 열 대상 스케일링\n",
    "    - 텍스트 분류 및 추천 시스템 등의 문제에서 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc9005",
   "metadata": {},
   "source": [
    "## 차원 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27dbc31",
   "metadata": {},
   "source": [
    "### 차원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7f468",
   "metadata": {},
   "source": [
    "- 차원 : 수학에서 공간 내 있는 점 등의 위치를 나타내기 위해 필요한 축의 개수\n",
    "- 매개변수 : 차원에서 사용된 수\n",
    "- 차원 축소 : 차원 (=변수의 수)를 줄이는 것, 차원이 크면 시각화 및 분석이 어렵기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade1da6",
   "metadata": {},
   "source": [
    "### 대표적인 차원 축소 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec71b9",
   "metadata": {},
   "source": [
    "1. PCA (주성분 분석)\n",
    "    - 목적 : n개의 변수만 사용하여 전체를 설명\n",
    "    - 고차원 데이터를 기존 분산을 최대한 보존하는 선형 독립의 새로운 변수로 변환\n",
    "    - 여러 변수 간 상관관계를 이용하여 대표 주성분을 추출\n",
    "\n",
    "2. LDA (선형 판별 분석)\n",
    "    - 데이터셋을 저차원 공간에 투영하여 차원을 축소\n",
    "    - PCA와의 차이 : 입력 데이터의 결정값 클래스를 최대한 분리할 수 있는 축을 찾음\n",
    "    - 클래스 간 분산은 Maximize, 클래스 내 분산은 Minimize\n",
    "    \n",
    "3. SVD (특이값 분해)\n",
    "    - 정사각행렬이 아닌 m*n 형태의 다양한 행렬을 분해\n",
    "\n",
    "4. MNF (비음수 행렬 분해)\n",
    "    - 하나의 객체정보를 음수를 포함하지 않은 두 개의 부분 정보로 인수분해\n",
    "    - 대량의 정보를 의미 특징과 의미 변수로 나누어 효율적으로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158e4703",
   "metadata": {},
   "source": [
    "### 차원축소가 필요한 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd341c",
   "metadata": {},
   "source": [
    "1. 차원의 저주 \n",
    "    - 차원이 커짐에 따라 공간의 범위가 기하급수적으로 증가해서 많은 표본이 필요해지는 현상\n",
    "    - 고차원의 데이터 분석은 많은 변수의 저장이 필요하며, 시간을 많이 필요로 함\n",
    "    \n",
    "2. 과적합 문제\n",
    "    - 고차원 문제를 풀다보면 너무 정교해져 일반화 결과를 도출할 수 없는 상황이 올 수 있음\n",
    "    \n",
    "3. 분석 및 시각화 용이성\n",
    "    - 저차원에서 데이터 구조를 분석하는 것이 더 쉬움\n",
    "    - 같은 이유로, 시각화도 용이"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
